\documentclass{article}
\input{style.sty}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\pgfplotsset{
  xticklabel={%
    $\mathsf{%
    \pgfmathtruncatemacro{\IntegerTick}{\tick}%
    \pgfmathprintnumberto[verbatim]{\tick}\tickAdjusted%
    \pgfmathparse{\IntegerTick == \tickAdjusted ? 1: 0}%
    \ifnum\pgfmathresult>0\relax\IntegerTick\else\fi%
    }$%
  },  
  yticklabel={%
    $\mathsf{%
    \pgfmathtruncatemacro{\IntegerTick}{\tick}%
    \pgfmathprintnumberto[verbatim]{\tick}\tickAdjusted%
    \pgfmathparse{\IntegerTick == \tickAdjusted ? 1: 0}%
    \ifnum\pgfmathresult>0\relax\IntegerTick\else\fi%
    }$%
  },  
}
\usetikzlibrary{intersections}
\usepackage{lipsum}  

\usepackage[
  paperwidth=90cm,
  paperheight=120cm,
  top=25cm,
  left=9cm,
  right=9cm,
]{geometry}


\usepackage{wallpaper}
\CenterWallPaper{1}{assets/background}

\usepackage{fontspec}
\setmainfont{Arial}

\usepackage[BoldFont, SlantFont]{xeCJK}
\setCJKmainfont{Microsoft JhengHei}

\usepackage[absolute]{textpos}
\TPGrid[80mm,390mm]{15}{12}

\parindent=0pt
\parskip=\baselineskip

\begin{document}
% disable page numbering
\thispagestyle{empty}
\membersize \textbf{第17組：朱劭璿、陳居廷}\hspace{20.5cm}\textbf{指導老師：陳嘉平 教授}
\bigskip

\titlesize \textbf{TSM-Net: 以對抗式時序壓縮自編碼器為基礎的音訊變速演算法 \\
TSM-Net: Temporal Compressing Autoencoder with Adversarial Losses for Time-Scale Modification on Audio Signals}

\begin{textblock}{7.0}(0,0)
\Head{Introduction} \\
\Large
With the advance of technologies and digitalization, we can store and reproduce multimedia content nowadays. An ubiquitous application regarding audio signals called time-scaled modification (TSM) is used in our daily life. It's also known as playback speed control in the video streaming platforms such as YouTube. With the power of artificial intelligence (AI) and modern computation hardware, however, we haven't discovered any method using AI to refine TSM algorithm and leverage the quality of the synthetic audio to the next level.

We proposed a novel TSM approach. While traditional methods use framing technique and spectral approaches use short-time Fourier transform to get high-level units. TSM-Net, our neural-network model encodes the raw audio into a high-level latent representation called Neuralgram. Since the resulting Neuralgram is a two-dimensional image with real values, we apply some existing image resizing techniques on the Neuralgram and decode it using our neural decoder to obtain the time-scaled audio. \\

\medskip
\Head{Related Works} \\
\Large
 Modeling audio is not a trivial task for neural networks. Models that directly generate raw audio waveform are known as vocoder which can be conditioned on some high-level abstract features such as linguistic features or spectrograms. In applications like text-to-speech (TTS) pipeline, the network often predicts the speech spectrogram of given texts, then uses a vocoder to get the raw audio. Modern neural-enabled vocoders bring the synthetic quality to a new level.

Decreasing the sampling rate to simplify the dimensionality is another option. However, the Nyquist-Shannon sampling theorem suggests that the low sampling rate would lead to serious aliasing. For example, suppose the signals are sampled non-uniformly for a better illustration, two signals with different frequency components are the aliases for each other in the discrete domain, represented as black dots.

\large \input{assets/alias-illus.tex}
\end{textblock}

\begin{textblock}{7.0}(8,0)
\Head{Methodology} \\
\Large \lipsum[3-3]
\large \input{assets/tsm-illus.tex}

\medskip

\Head{Experiment} \\
\Large \lipsum[4-4]

\medskip
\Head{Conclusion} \\
\Large \lipsum[5-5]
\end{textblock}


\end{document}
